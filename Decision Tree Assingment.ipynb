{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.What is a Decision Tree, and how does it work ?\n",
    "\n",
    "#  Answer:- A Decision Tree is a machine learning method that makes decisions based on data. It has a tree-like structure with:\n",
    "\n",
    "# Root Node: Represents the entire dataset, starts the tree.\n",
    "\n",
    "# Decision Nodes: Points where the data splits based on attributes.\n",
    "\n",
    "# Leaf Nodes: Final decisions or outcomes.\n",
    "\n",
    "# Splitting: Process of dividing nodes into sub-nodes.\n",
    "\n",
    "# Pruning: Removing unnecessary nodes to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What are impurity measures in Decision Trees ?\n",
    "\n",
    "# Answer:- Impurity measures in decision trees help determine how mixed or \"impure\" the samples in a node are. \n",
    "# The goal is to find splits that result in the most homogeneous child nodes. Some common impurity measures include:\n",
    "\n",
    "# Gini Impurity: Measures the likelihood of incorrect classification.\n",
    "\n",
    "# Entropy (Information Gain): Measures disorder or uncertainty.\n",
    "\n",
    "# Variance Reduction: Used in regression trees to measure the reduction in variance.\n",
    "\n",
    "# Mean Squared Error (MSE): Measures the average of squared differences between actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. What is the mathematical formula for Gini Impurity?\n",
    "\n",
    "# Answer:-\n",
    "# The Gini Impurity is calculated using the formula:\n",
    "# Gini = 1 - Σ (p_i)^2\n",
    "# where p_i is the probability of an element being classified to a particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. What is the mathematical formula for Entropy?\n",
    "\n",
    "# Answer:-\n",
    "# The Entropy is calculated using the formula:\n",
    "# Entropy = - Σ (p_i * log2(p_i))\n",
    "# where p_i is the probability of an element being classified to a particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. What is Information Gain, and how is it used in Decision Trees?\n",
    "\n",
    "# Answer:-\n",
    "# Information Gain is a measure used in decision trees to determine which feature to split the data on at each step.\n",
    "# It quantifies the reduction in entropy (uncertainty) achieved by partitioning the data based on a given feature.\n",
    "# The feature with the highest Information Gain is chosen for the split.\n",
    "\n",
    "# The formula for Information Gain is:\n",
    "# Information Gain = Entropy(parent) - [Weighted Average] * Entropy(children)\n",
    "\n",
    "# In other words, it calculates the difference between the entropy of the parent node and the weighted sum of the entropies of the child nodes.\n",
    "# This helps in selecting the feature that provides the most significant reduction in uncertainty, leading to more homogeneous child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. What is the difference between Gini Impurity and Entropy?\n",
    "\n",
    "# Answer:-\n",
    "# Both Gini Impurity and Entropy are measures of impurity used in decision trees to determine the best splits. \n",
    "# However, they have some differences:\n",
    "\n",
    "# Gini Impurity:\n",
    "# - Measures the likelihood of incorrect classification of a randomly chosen element.\n",
    "# - Formula: Gini = 1 - Σ (p_i)^2\n",
    "# - Computationally simpler and faster.\n",
    "# - Tends to create binary splits.\n",
    "\n",
    "# Entropy:\n",
    "# - Measures the amount of disorder or uncertainty in the data.\n",
    "# - Formula: Entropy = - Σ (p_i * log2(p_i))\n",
    "# - More computationally intensive.\n",
    "# - Can create multi-way splits.\n",
    "\n",
    "# In practice, both measures often lead to similar results, but Gini Impurity is preferred for its computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. What is the mathematical explanation behind Decision Trees?\n",
    "\n",
    "# Answer:-\n",
    "# Decision Trees use a tree-like model of decisions and their possible consequences. The key mathematical concepts include:\n",
    "\n",
    "# 1. Splitting Criteria:\n",
    "#    - Decision trees split nodes based on certain criteria to maximize the homogeneity of the resulting sub-nodes.\n",
    "#    - Common criteria include Gini Impurity and Entropy (Information Gain).\n",
    "\n",
    "# 2. Gini Impurity:\n",
    "#    - Measures the impurity of a node.\n",
    "#    - Formula: Gini = 1 - Σ (p_i)^2\n",
    "#    - p_i is the probability of an element being classified to a particular class.\n",
    "\n",
    "# 3. Entropy:\n",
    "#    - Measures the disorder or uncertainty in the data.\n",
    "#    - Formula: Entropy = - Σ (p_i * log2(p_i))\n",
    "#    - p_i is the probability of an element being classified to a particular class.\n",
    "\n",
    "# 4. Information Gain:\n",
    "#    - Measures the reduction in entropy achieved by partitioning the data based on a given feature.\n",
    "#    - Formula: Information Gain = Entropy(parent) - [Weighted Average] * Entropy(children)\n",
    "\n",
    "# 5. Recursive Partitioning:\n",
    "#    - The process of splitting the dataset into subsets, which is repeated recursively.\n",
    "#    - The recursion is completed when the subsets at a node all have the same value of the target variable, or when splitting no longer adds value to the predictions.\n",
    "\n",
    "# 6. Pruning:\n",
    "#    - The process of removing sections of the tree that provide little power to classify instances.\n",
    "#    - Helps in reducing overfitting and improving the model's generalization.\n",
    "\n",
    "# 7. Cost Function:\n",
    "#    - Decision trees aim to minimize a cost function, which is often the impurity measure (Gini or Entropy) or a loss function (e.g., Mean Squared Error for regression trees).\n",
    "\n",
    "# These mathematical concepts form the foundation of how decision trees make decisions and classify data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. What is Pre-Pruning in Decision Trees?\n",
    "\n",
    "# Answer:-\n",
    "# Pre-pruning, also known as early stopping, is a technique used to prevent overfitting in decision trees by halting the tree growth early.\n",
    "# It involves setting conditions to stop the splitting of nodes before the tree becomes too complex.\n",
    "# Some common pre-pruning criteria include:\n",
    "\n",
    "# 1. Maximum Depth: Limiting the maximum depth of the tree.\n",
    "# 2. Minimum Samples per Leaf: Requiring a minimum number of samples in each leaf node.\n",
    "# 3. Minimum Samples per Split: Requiring a minimum number of samples to perform a split.\n",
    "# 4. Maximum Number of Nodes: Limiting the total number of nodes in the tree.\n",
    "# 5. Maximum Leaf Nodes: Limiting the number of leaf nodes.\n",
    "\n",
    "# By applying these criteria, pre-pruning helps in reducing the complexity of the tree, making it more generalizable and less prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. What is Post-Pruning in Decision Trees?\n",
    "\n",
    "# Answer:-\n",
    "# Post-pruning, also known as pruning, is a technique used to reduce the complexity of a decision tree after it has been fully grown.\n",
    "# The goal is to remove sections of the tree that provide little power to classify instances, thereby improving the model's generalization and reducing overfitting.\n",
    "# Post-pruning involves the following steps:\n",
    "\n",
    "# 1. Grow the full tree: Build the decision tree to its maximum depth, allowing it to overfit the training data.\n",
    "# 2. Evaluate subtrees: Assess the performance of subtrees and determine if removing certain branches improves the overall accuracy on a validation set.\n",
    "# 3. Prune branches: Remove branches that do not contribute significantly to the model's performance, based on criteria such as error rates or impurity measures.\n",
    "# 4. Simplify the tree: The result is a simpler, more generalizable tree that performs better on unseen data.\n",
    "\n",
    "# Common post-pruning techniques include:\n",
    "# - Cost Complexity Pruning (CCP): Balances the trade-off between tree complexity and accuracy by introducing a penalty for the number of leaves.\n",
    "# - Reduced Error Pruning: Removes branches only if it does not increase the error rate on a validation set.\n",
    "\n",
    "# Post-pruning helps in creating a more robust and interpretable decision tree model by eliminating unnecessary complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. What is the difference between Pre-Pruning and Post-Pruning?\n",
    "\n",
    "# Answer:-\n",
    "# Pre-Pruning and Post-Pruning are techniques used to prevent overfitting in decision trees, but they differ in their approach and timing:\n",
    "\n",
    "# Pre-Pruning (Early Stopping):\n",
    "# - Stops the growth of the tree early by setting conditions to halt splitting.\n",
    "# - Criteria include maximum depth, minimum samples per leaf, minimum samples per split, maximum number of nodes, and maximum leaf nodes.\n",
    "# - Prevents the tree from becoming too complex during the initial construction.\n",
    "# - Can be faster as it avoids growing a large tree, but may miss important splits.\n",
    "\n",
    "# Post-Pruning (Pruning):\n",
    "# - Allows the tree to grow to its full depth, potentially overfitting the training data.\n",
    "# - Evaluates and removes branches that do not contribute significantly to the model's performance.\n",
    "# - Techniques include Cost Complexity Pruning (CCP) and Reduced Error Pruning.\n",
    "# - Simplifies the tree after it has been fully grown, improving generalization.\n",
    "# - Can be more effective as it considers the entire tree structure, but may be computationally intensive.\n",
    "\n",
    "# In summary, Pre-Pruning stops the tree growth early based on predefined criteria, while Post-Pruning removes unnecessary branches after the tree is fully grown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. What is a Decision Tree Regressor?\n",
    "\n",
    "# Answer:-\n",
    "# A Decision Tree Regressor is a machine learning model used for regression tasks, where the goal is to predict a continuous target variable.\n",
    "# It works similarly to a Decision Tree Classifier but is designed to handle continuous output values.\n",
    "\n",
    "# Key concepts of a Decision Tree Regressor include:\n",
    "\n",
    "# 1. Splitting Criteria:\n",
    "#    - The tree splits nodes based on criteria that minimize the variance or mean squared error (MSE) of the target variable in the resulting sub-nodes.\n",
    "\n",
    "# 2. Variance Reduction:\n",
    "#    - Measures the reduction in variance achieved by partitioning the data based on a given feature.\n",
    "#    - The feature that results in the highest variance reduction is chosen for the split.\n",
    "\n",
    "# 3. Mean Squared Error (MSE):\n",
    "#    - Measures the average of the squared differences between the actual and predicted values.\n",
    "#    - The tree aims to minimize the MSE at each split.\n",
    "\n",
    "# 4. Recursive Partitioning:\n",
    "#    - The process of splitting the dataset into subsets, which is repeated recursively.\n",
    "#    - The recursion continues until a stopping criterion is met, such as a maximum depth or minimum number of samples per leaf.\n",
    "\n",
    "# 5. Leaf Nodes:\n",
    "#    - Represent the final predictions of the model.\n",
    "#    - Each leaf node contains the mean value of the target variable for the samples in that node.\n",
    "\n",
    "# 6. Pruning:\n",
    "#    - Techniques like pre-pruning and post-pruning can be applied to prevent overfitting and improve the model's generalization.\n",
    "\n",
    "# Decision Tree Regressors are interpretable and can capture non-linear relationships in the data, making them useful for various regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. What are the advantages and disadvantages of Decision Trees?\n",
    "\n",
    "# Answer:-\n",
    "# Advantages of Decision Trees:\n",
    "# 1. Interpretability: Decision trees are easy to understand and interpret. The tree structure allows for clear visualization of the decision-making process.\n",
    "# 2. Non-linearity: Decision trees can capture non-linear relationships between features and the target variable.\n",
    "# 3. Feature Importance: Decision trees provide insights into the importance of different features in making predictions.\n",
    "# 4. No Need for Feature Scaling: Decision trees do not require feature scaling (e.g., normalization or standardization).\n",
    "# 5. Handling Missing Values: Decision trees can handle missing values by assigning the most common value or using surrogate splits.\n",
    "# 6. Versatility: Decision trees can be used for both classification and regression tasks.\n",
    "\n",
    "# Disadvantages of Decision Trees:\n",
    "# 1. Overfitting: Decision trees are prone to overfitting, especially when the tree is deep and complex. Pruning techniques are needed to mitigate this issue.\n",
    "# 2. Instability: Small changes in the data can lead to significant changes in the tree structure, making decision trees unstable.\n",
    "# 3. Bias: Decision trees can be biased towards features with more levels or categories.\n",
    "# 4. Computational Complexity: Building a decision tree can be computationally expensive, especially for large datasets with many features.\n",
    "# 5. Limited Expressiveness: Decision trees may struggle to capture complex patterns in the data compared to other models like ensemble methods (e.g., Random Forests, Gradient Boosting).\n",
    "\n",
    "# In summary, decision trees are interpretable and versatile models but require careful tuning and pruning to avoid overfitting and instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. How does a Decision Tree handle missing values?\n",
    "\n",
    "# Answer:-\n",
    "# Decision Trees can handle missing values in several ways:\n",
    "\n",
    "# 1. Surrogate Splits:\n",
    "#    - When a primary split feature has missing values, the tree can use surrogate splits.\n",
    "#    - Surrogate splits are alternative features that closely mimic the primary split.\n",
    "#    - The tree uses the surrogate feature to make the split decision for instances with missing values in the primary feature.\n",
    "\n",
    "# 2. Imputation:\n",
    "#    - Missing values can be imputed before training the decision tree.\n",
    "#    - Common imputation methods include filling missing values with the mean, median, or mode of the feature.\n",
    "\n",
    "# 3. Missing Value as a Separate Category:\n",
    "#    - For categorical features, missing values can be treated as a separate category.\n",
    "#    - This allows the tree to learn patterns specific to missing values.\n",
    "\n",
    "# 4. Weighted Splits:\n",
    "#    - Some decision tree algorithms use weighted splits to handle missing values.\n",
    "#    - The algorithm assigns weights to different branches based on the proportion of non-missing values.\n",
    "\n",
    "# These methods help decision trees to effectively handle missing values and make accurate predictions even when some data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. How does a Decision Tree handle categorical features?\n",
    "\n",
    "# Answer:-\n",
    "# Decision Trees can handle categorical features in the following ways:\n",
    "\n",
    "# 1. One-Hot Encoding:\n",
    "#    - Categorical features are converted into binary vectors using one-hot encoding.\n",
    "#    - Each category is represented as a separate binary feature.\n",
    "#    - This allows the decision tree to treat each category as a distinct feature.\n",
    "\n",
    "# 2. Label Encoding:\n",
    "#    - Categorical features are converted into integer labels using label encoding.\n",
    "#    - Each category is assigned a unique integer value.\n",
    "#    - The decision tree can then use these integer values to make splits.\n",
    "\n",
    "# 3. Direct Handling:\n",
    "#    - Some decision tree algorithms can directly handle categorical features without encoding.\n",
    "#    - The tree can split on categorical features by evaluating each category separately.\n",
    "#    - This approach is often used in decision tree implementations like CART (Classification and Regression Trees).\n",
    "\n",
    "# 4. Binary Splits:\n",
    "#    - For categorical features with many levels, the tree can create binary splits.\n",
    "#    - The tree evaluates different combinations of categories to find the best split.\n",
    "#    - This helps in reducing the complexity of the tree.\n",
    "\n",
    "# These methods enable decision trees to effectively handle categorical features and make accurate predictions based on categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. What are some real-world applications of Decision Trees?\n",
    "\n",
    "# Answer:-\n",
    "# Real-world applications of Decision Trees:\n",
    "\n",
    "# 1. Medical Diagnosis:\n",
    "#    - Decision trees are used to diagnose diseases based on patient symptoms and medical history.\n",
    "#    - They help in identifying the most likely conditions and recommending appropriate treatments.\n",
    "\n",
    "# 2. Customer Segmentation:\n",
    "#    - Businesses use decision trees to segment customers based on purchasing behavior, demographics, and preferences.\n",
    "#    - This helps in targeting marketing campaigns and improving customer satisfaction.\n",
    "\n",
    "# 3. Fraud Detection:\n",
    "#    - Decision trees are employed to detect fraudulent activities in financial transactions.\n",
    "#    - They analyze patterns and anomalies in transaction data to identify potential fraud.\n",
    "\n",
    "# 4. Credit Scoring:\n",
    "#    - Financial institutions use decision trees to assess the creditworthiness of loan applicants.\n",
    "#    - They evaluate factors such as income, credit history, and employment status to make lending decisions.\n",
    "\n",
    "# 5. Churn Prediction:\n",
    "#    - Companies use decision trees to predict customer churn and identify factors contributing to customer attrition.\n",
    "#    - This helps in implementing retention strategies to reduce churn rates.\n",
    "\n",
    "# 6. Manufacturing Quality Control:\n",
    "#    - Decision trees are used in manufacturing to monitor and control product quality.\n",
    "#    - They help in identifying defects and determining the root causes of quality issues.\n",
    "\n",
    "# 7. Environmental Monitoring:\n",
    "#    - Decision trees are applied in environmental science to predict air and water quality.\n",
    "#    - They analyze data from sensors and weather stations to forecast pollution levels.\n",
    "\n",
    "# 8. Human Resources:\n",
    "#    - HR departments use decision trees to evaluate job applicants and make hiring decisions.\n",
    "#    - They assess factors such as experience, skills, and qualifications to select the best candidates.\n",
    "\n",
    "# 9. Agriculture:\n",
    "#    - Decision trees are used in agriculture to predict crop yields and optimize farming practices.\n",
    "#    - They analyze factors such as soil quality, weather conditions, and pest infestations.\n",
    "\n",
    "# 10. Sentiment Analysis:\n",
    "#    - Decision trees are employed in natural language processing to analyze sentiment in text data.\n",
    "#    - They help in understanding customer opinions and feedback from social media and reviews.\n",
    "\n",
    "# These applications demonstrate the versatility and effectiveness of decision trees in various domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Accuracy Score :1.0\n",
      "--------------------\n",
      "-----------------------------------------------------------------\n",
      "Important Features :[0.01911002 0.         0.55727376 0.42361622]\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 16. Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data=load_iris()\n",
    "\n",
    "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df[\"target\"]=data.target\n",
    "\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "print(\"-----\"*4)\n",
    "print(f\"Accuracy Score :{acc}\")\n",
    "print(\"-----\"*4)\n",
    "\n",
    "print(\"-----\"*13)\n",
    "print(f\"Important Features :{clf.feature_importances_}\")\n",
    "print(\"-----\"*13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Important Features :[0.         0.02288528 0.         0.         0.         0.\n",
      " 0.         0.70583856 0.00858198 0.         0.         0.\n",
      " 0.         0.01356259 0.00200417 0.00715165 0.         0.01716396\n",
      " 0.         0.         0.03953682 0.10548036 0.         0.06730262\n",
      " 0.01049202 0.         0.         0.         0.         0.        ]\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 17. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the feature importances.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier(criterion=\"gini\")\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"-----\"*13)\n",
    "print(f\"Important Features :{clf.feature_importances_}\")\n",
    "print(\"-----\"*13)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Accuracy Score :0.96\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 18.  Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the model accuracy.\n",
    "\n",
    "# Answer:- \n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "print(\"-----\"*4)\n",
    "print(f\"Accuracy Score :{acc :.2f}\")\n",
    "print(\"-----\"*4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Mean Squared Error :0.52\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# 19.  Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean Squared Error (MSE).\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X,y=fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "regression=DecisionTreeRegressor()\n",
    "regression.fit(X_train,y_train)\n",
    "\n",
    "y_pred=regression.predict(X_test)\n",
    "\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(\"-----\"*5)\n",
    "print(f\"Mean Squared Error :{mse :.2f}\")\n",
    "print(\"-----\"*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 24\u001b[0m\n\u001b[0;32m     17\u001b[0m dot_data\u001b[38;5;241m=\u001b[39mexport_graphviz(clf,out_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     18\u001b[0m                          feature_names\u001b[38;5;241m=\u001b[39mload_breast_cancer()\u001b[38;5;241m.\u001b[39mfeature_names,\n\u001b[0;32m     19\u001b[0m                          class_names\u001b[38;5;241m=\u001b[39mload_breast_cancer()\u001b[38;5;241m.\u001b[39mtarget_names,\n\u001b[0;32m     20\u001b[0m                          filled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,rounded\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,special_characters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m graph\u001b[38;5;241m=\u001b[39mpydotplus\u001b[38;5;241m.\u001b[39mgraph_from_dot_data(dot_data)\n\u001b[1;32m---> 24\u001b[0m Image(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydotplus\\graphviz.py:1797\u001b[0m, in \u001b[0;36mDot.__init__.<locals>.<lambda>\u001b[1;34m(f, prog)\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[38;5;66;03m# Automatically creates all the methods enabling the creation\u001b[39;00m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;66;03m# of output in any of the supported formats.\u001b[39;00m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frmt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformats:\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\n\u001b[0;32m   1796\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m frmt,\n\u001b[1;32m-> 1797\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m f\u001b[38;5;241m=\u001b[39mfrmt, prog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1798\u001b[0m     )\n\u001b[0;32m   1799\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m frmt]\n\u001b[0;32m   1800\u001b[0m     f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1801\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m'''Refer to the docstring accompanying the'''\u001b[39;00m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m''''create' method for more information.'''\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydotplus\\graphviz.py:1959\u001b[0m, in \u001b[0;36mDot.create\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1957\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogs \u001b[38;5;241m=\u001b[39m find_graphviz()\n\u001b[0;32m   1958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1959\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvocationException(\n\u001b[0;32m   1960\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraphViz\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms executables not found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prog \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogs:\n\u001b[0;32m   1963\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvocationException(\n\u001b[0;32m   1964\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraphViz\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms executable \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m prog)\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "# 20. Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import export_graphviz,DecisionTreeClassifier\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "dot_data=export_graphviz(clf,out_file=None,\n",
    "                         feature_names=load_breast_cancer().feature_names,\n",
    "                         class_names=load_breast_cancer().target_names,\n",
    "                         filled=True,rounded=True,special_characters=True)\n",
    "\n",
    "graph=pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Accuracy Score of Maximum Depth - 3 :1.00\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "Accuracy Score of Fully grown tree :1.00\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 21. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its accuracy with a fully grown tree.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X,y=load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_max_depth_3=DecisionTreeClassifier(max_depth=3,random_state=42)\n",
    "clf_max_depth_3.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf_max_depth_3.predict(X_test)\n",
    "\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "print(\"------\"*7)\n",
    "print(f\"Accuracy Score of Maximum Depth - 3 :{acc :.2f}\")\n",
    "print(\"------\"*7)\n",
    "\n",
    "clf=DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "print(\"------\"*7)\n",
    "print(f\"Accuracy Score of Fully grown tree :{acc :.2f}\")\n",
    "print(\"------\"*7)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Accuracy Score of  minimum sample split 5 :0.02\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "Accuracy Score of Default:0.02\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 22. Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its accuracy with a default tree.\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X,y=load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_min_sample_5=DecisionTreeClassifier(min_samples_split=5,random_state=42)\n",
    "clf_min_sample_5.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf_min_sample_5.predict(X_test)\n",
    "\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "print(\"------\"*7)\n",
    "print(f\"Accuracy Score of  minimum sample split 5 :{acc :.2f}\")\n",
    "print(\"------\"*7)\n",
    "\n",
    "clf=DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "print(\"------\"*7)\n",
    "print(f\"Accuracy Score of Default:{acc :.2f}\")\n",
    "print(\"------\"*7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Accuracy Score without Feature Scaling: 0.79\n",
      "------------------------------------------\n",
      "Accuracy Score with Feature Scaling: 0.82\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 23. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its accuracy with unscaled data.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y=make_classification(n_samples=1000,n_features=20,n_informative=15,n_redundant=5,random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "\n",
    "# Scaling\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "clf_scaled=DecisionTreeClassifier()\n",
    "clf_scaled.fit(X_train_scaled,y_train)\n",
    "scaled_y_pred=clf_scaled.predict(X_test_scaled)\n",
    "\n",
    "acc_scaled=accuracy_score(y_test,scaled_y_pred)\n",
    "\n",
    "print(\"------\" * 7)\n",
    "print(f\"Accuracy Score without Feature Scaling: {acc:.2f}\")\n",
    "print(\"------\" * 7)\n",
    "print(f\"Accuracy Score with Feature Scaling: {acc_scaled:.2f}\")\n",
    "print(\"------\" * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Accuracy Score with One-vs-Rest strategy :0.91\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 24. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass classification.\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data=load_wine()\n",
    "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df[\"target\"]=data.target\n",
    "\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_ovr=OneVsRestClassifier(DecisionTreeClassifier())\n",
    "clf_ovr.fit(X_train,y_train)\n",
    "y_pred=clf_ovr.predict(X_test)\n",
    "\n",
    "acc=accuracy_score(y_test,y_pred)\n",
    "print(\"--------\"*6)\n",
    "print(f\"Accuracy Score with One-vs-Rest strategy :{acc:.2f}\")\n",
    "print(\"--------\"*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "Important Features :\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.70583856 0.         0.         0.01356259 0.\n",
      " 0.         0.         0.00915582 0.         0.         0.01716396\n",
      " 0.         0.         0.03953682 0.13694761 0.03064992 0.0366527\n",
      " 0.01049202 0.         0.         0.         0.         0.        ]\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 25. Write a Python program to train a Decision Tree Classifier and display the feature importance scores.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"-----\"*13)\n",
    "print(f\"Important Features :\\n{clf.feature_importances_}\")\n",
    "print(\"-----\"*13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Mean Squared Error of max depth 5: 3818.07\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "Mean Squared Error of unrestricted: 5697.79\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 26. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance with an unrestricted tree.\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf_max_depth_5 = DecisionTreeRegressor(random_state=42, max_depth=5)\n",
    "clf_max_depth_5.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_max_depth_5.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"------\" * 7)\n",
    "print(f\"Mean Squared Error of max depth 5: {mse:.2f}\")\n",
    "print(\"------\" * 7)\n",
    "\n",
    "clf = DecisionTreeRegressor(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"------\" * 7)\n",
    "print(f\"Mean Squared Error of unrestricted: {mse:.2f}\")\n",
    "print(\"------\" * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAK9CAYAAADIapagAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWwFJREFUeJzt3QmcVWX9P/CHfRHBBWRRBEVScU0QwiWzMEwzU0szU6QyNbc0NXeUyi01/au5lbullmiWhRmlpZKoqKW4a0DKIqYgIPv9v76PvzvNwAADnmG29/v1usycc88995x77h3O5z7P8z3NSqVSKQEAAPCxNP94DwcAACAIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcATcTDDz+cmjVrln+u7mN/85vfpNr26quvps9//vOpU6dO+Tnvu+++1FAdfvjhqXfv3qv12HPPPTfvf2P273//O+/jzTffnBrrZwdoWoQroMZ+9rOf5ROMQYMG1fWm0IgNGzYs/etf/0o//vGP02233ZYGDBhQa8/19ttv5xDz7LPP1tpz8PFNmDAhH6cIY7X9N66+B72P4/HHH8+v4/vvv1/XmwKNlnAF1Ngdd9yRv4UfN25ceu211+p6c2iEPvzwwzR27Nj0rW99Kx177LHpG9/4Rtpoo41qNVydd955tRaubrjhhvTyyy+v1mPPOuus/HrwUbiK41RX4erTn/50Phbxs6GHq3gdhSuoPcIVUCNvvvlm/o/5sssuS126dMlBq76aM2dOXW8Cq+mdd97JP9dZZ516+X6YO3fuKi3fqlWr1KZNm9V6rpYtW6a2bduu1mMpVvPmzfOxiJ8AK+KvBFAjEabWXXfdtPfee6evfOUryw1X8Y3oiSeemFu44qQyWh0OO+ywNGPGjIpl5s2bl7umfOITn8gnLN27d0/7779/ev3111c4vqG68RkxpqVDhw75sXvttVdae+210yGHHJLv+/vf/56++tWvpo033jhvS8+ePfO2Vdca8NJLL6UDDzwwB8d27dqlzTffPJ155pn5vr/+9a/5ee+9995lHvfLX/4y3xetLdV56qmn8v233HLLMvc9+OCD+b7f//73efqDDz5I3/ve9ypeuw022CDtscceafz48WlFJk6cmL773e/mbY5tX3/99fN+1+Rb/s985jNp6623Tk8//XTaaaed8uM32WSTdO2111a7/JIlS3J3vTiucew+97nPLdOKuSqve2XxnujVq1f+/ZRTTsmvTeXxSs8880z6whe+kDp27JiPeTz3P/7xjyrriPdGPO6RRx7Jr0m8hstr+Yr314477ph/Hz58eH5c5fdX5dcmWizat2+fzjjjjHzfb3/72/xZ6NGjR97HPn36pB/+8Idp8eLFKxxzVX4PX3LJJen666/Pj4vHx3Y8+eSTKx1zFdPRohfj0GLb4rFbbbVVGj16dLX7F10q4zjF81x33XU1HsdV02NY/vy99dZb6ctf/nL+PT5DJ5988jKvRfxtiOVjLF2E5+j+WZMWlDgesS1h9913rzhOlf8+/PGPf0y77rprWmuttfLfgDg2L7zwQpX1TJ06NR/neD/EPsXfnX333bficxLHKR4T753yc8R7oPxaLv2c5fdHtKrFdsX7Y8MNN0wXX3xxtZ/RL33pS3n74j0Zr2X587+ycVw1/bvwxBNPpD333DO/vrEtu+22W3rssccq7o9jH5+rEJ/x8j6W9/+hhx5Ku+yySz42cRzj70n5/Q7UXMtVWBZowiJMRQBq3bp1Ovjgg9M111yTTwbLJ6dh9uzZ+QTnxRdfTN/85jfTDjvskEPV/fffn/7zn/+kzp075xOuL37xi2nMmDHpa1/7WjrhhBPyyUP8x/7888/nk8BVtWjRojR06NB8YhAnrXFiEX7961/nloajjz46B47oznjllVfmbYn7yv75z3/m7Y5Whu985zv5JCbC2u9+97scJOIkKk4u4zXYb7/9lnldYpsHDx5c7bbFye2mm26a7r777nwyWdldd92VA2tsezjqqKNywYg4ee7Xr196991306OPPppfz3gtlyeOQ7QqxusZJ45xshTHJ7Y7TvzKr8fyvPfeezmYRriMYxvbGq9ZHOs4jpVdeOGF+dv7OHmeOXNmPpGMMBsndmU1fd2XFu+vOLGLE8/YjtimOMkLcdIbxyiC1amnnpqPVYSF2Mc4GV56HGAEqzjJP+ecc5bbcrXlllumkSNH5mXiuMf6Q4TMsjgGEejitY0uil27dq044Y9tO+mkk/LPv/zlL3k9s2bNSj/5yU/SykQoj/f9kUcemU9w43WM/X/jjTfyvq1IvCdGjRqV9zGCxP/7f/8vHXDAAWnSpEn59S4H0TjRjgAR3cDicxf7Gq9JTazKMYx1x3s4jkF8/v785z+nSy+9NH8u4vGhVCrlIBPbHu/zeO3jy4qlPxPViWB7/PHH5/2Mk/14bCj/jHF5sZ7Yhosuuihvd7z/4+9BvA7lcBuvUbyPjjvuuDxv+vTp+e9OvG4xffnll+f74niWv1gpH+8VfXbidY5jF5+f+Pz+4Ac/SNtss01+34R4/332s59NU6ZMyX/vunXrlo9/fGlTEzX5uxDvv3i+/v37pxEjRuTP6E033ZSfN4LywIED8za+8sor6Ve/+lX66U9/mv8eh3hPxOsSf5e33Xbb/D6JEBdfmlQOZ0ANlQBW4qmnnirFn4uHHnooTy9ZsqS00UYblU444YQqy51zzjl5uVGjRi2zjnhMuPHGG/Myl1122XKX+etf/5qXiZ+Vvfnmm3n+TTfdVDFv2LBhed5pp522zPrmzp27zLwLLrig1KxZs9LEiRMr5n36058urb322lXmVd6ecPrpp5fatGlTev/99yvmTZ8+vdSyZcvSiBEjSisSj23VqlXpv//9b8W8+fPnl9ZZZ53SN7/5zYp5nTp1Kh1zzDGlVVXdfo4dOza/LrfeemvFvOpe19122y3Pu/TSS6ts2/bbb1/aYIMNSgsWLKjy2C233DLfX3bFFVfk+f/6179W+XWvTvkY/+QnP6ky/8tf/nKpdevWpddff71i3ttvv52PWxy/snhvxON32WWX0qJFi0or8+STTy7znlr6tbn22muXua+6fTzyyCNL7du3L82bN6/K+7NXr17L7N/6669f5f3w29/+Ns//3e9+VzEv3ldL/zcd0/E6vPbaaxXznnvuuTz/yiuvrJi3zz775G156623Kua9+uqr+f1ak//6a3oMy5+/kSNHVln2k5/8ZKl///4V0/fdd19e7uKLL66YF8dn1113Xe7rX9mvf/3rav8mfPDBB/lzdMQRR1SZP3Xq1Px5Ks9/7733qn1fLW2rrbbKx31pK/rsVP6MxWejW7dupQMOOKBiXny2Yrl4Dco+/PDD0hZbbFHtPi1tZX8X4u9U3759S0OHDq3yNyuO4SabbFLaY489KubF/sdzxvuwsp/+9Kd5/jvvvLPCbQFWTrdAYKWidSa+wY2uLyG+aT/ooIPSnXfeWaXrzz333JO22267ZVp3yo8pLxPfmMY3xMtbZnWUvyGvLLq4lcW3x9GKFq0ScY4a32iXx/j87W9/yy000QVqedsTXRvnz59fpRR5tDxFq1m0aKxIvFYLFy7MrQ1lf/rTn3KXqLivLFptogUoiiysisr7Gc8T32xvttlmeX0r61JYHtsTLShl0WIV0/HNfnSJqyy6VcX9ZeXWnmhxWZXXfVXEeyxer+h2Fq2AZdEq8/Wvfz1/ix8tRpUdccQRqUWLFunjim/wY5+XVnkfowUq9jFei2g1iS6mKxPHPVotV/Q6Ls+QIUOqtPBGa0O06JUfG69XtB7F6xXdFsviPVFuTVmZVT2G0bpSWexP5X35wx/+kN9nlT+ncXyq+zuwKqLlKT5H0dIZ21i+xbqjJa3cOhT7E+/b6IIXrU1FiVauyp//eI5oJaq879FlM7oLRrfAsuiqGe/RmljZ34UoxhKXL4jPQnz2y69BHLfoOht/36I778qeo9zddWXLAismXAErFCdqEaIiWEVRi+gqErc4cZk2bVru3lcWXeliDMKKxDLRlz9OtIoS66puXE1094kxHuutt17FWJAYhxCiS1sonwStbLu32GKL3AWy8liz+P1Tn/pUPmldkQic8fgIY2Xxe4TM6LZTFl3DomtkdEGME7QYI1GTk+0YBxNd0uJxEQZivbGvcdJZ3s8ViRPwGAtSWYyHC0uP21o6gJYDQuUT1pq87qsiAnCElnjfLC26hsXJ4OTJk6vMjzElRYiT4sphsiy6UcWXCDG+JYJN7GP5JLsm+1iT17Gmjy0/vvzYCMXxnqjufbmy9+rqHMMICkt3N6y8PeUxRxGGy908y6o7pqsiQkWIz1FsQ+VbBPJ4LUJ8LqLLYIzNii+KoqthfN5iHNbHEX93lv5SqLp9jzC89HI1PRYr+7tQfg2ia+TSr8HPf/7z/KXQyt6TEfZ33nnn9O1vfzu/PtENNroHC1qw6oy5AlYo+vLHWIEIWHFbWgSMuOBrkZbXgrX0APmyOHFauopXLBuDvv/73//mMRARbiJAxMD7OGlcnZOGaL2KMRMx7iROWKKYwlVXXVWjx8bJS4zfim+UY5xMjEOLb9srh8wYsxHf+MdYlDgxjLE7cUIYLV4ranGIb/9jfEUMeo+xX+WL78YJUtEnR8trDfqox1rtvO6ro3LLS9HridAaQSNCVYxPiRPnCBjRShj7XJN9XNnrWFuPrYlVPYZFtBCurvK2xLirGMu0tMqfr/h87LPPPrkYSBSTOPvss9MFF1yQ/8Z98pOfXK3nr+1jUZO/C+XXIOZvv/321a5j6VBb3fs8Wriipe+BBx7IrW3xBVCE1njOujzG0NAIV8AKRXiK6lRXX331MvfFf+7xH35Ulov/nOMkM75hXZFYJrq4RPe15Q3cL3+Lv3QlsfgGuKbiIrQxeDuq9EUoqtyNqLJyN7OVbXeIsBIFDGJAeLQMxPZX7ta3IrFcFBaIbpHxzXB0Y4v1LS2+3Y9CBXGLb91jwHqEshWFq+iqGN9aRxGByhUZa3otm+huFF2IKrdexWsXKle6K/J1XxXxDXwU5ajuelHRBS+CdXyrvzpWpytqdC2L7lfx/q983aNo2a0P4vMaYa+6a9HV5Pp0tXEMowpktHJH0ZvKJ/o1vQbY8o5TuXtk7HN0l1yZWP773/9+vkWLT4SR+NzcfvvtK3yejyP2PQrLROCqvP5VuVbgiv4ulF+DCPsrew1WtH/xOYpuhHGLS26cf/75ubBHBK6avLbAR3QLBJYrAkScQEYVqSi/vvQtqlfFeJNohSlX43ruueeqLVle/iY3lonWm+pafMrLxMlIfFMa36QufYHPmip/01r5G+T4/YorrljmxD1OkG+88cbcFaq67SmL7nZxMhMnYhE6o0pYueLWykT3taggFt8Gxy1OliqfmEdrwdJdd+KEMbrsRSvZyvZ16W2Nym7La+lbWowbi8p7ZQsWLMjT8dpE9bFVUdPXfVXXGa2jMR6kcjfF6JYaVdeiKlycWK6OcqBclYuqVreP8ZqtyvuzNsX2xclwtNBUHqcTJ/PRLa4mjy/6GEblx3ifRRW/snh/xvv04xynqBAYxz6CQHxhs7zrpkW30vjCobIIJdGKXPnzFc9T9AV2Yxuj1a/8dzLEtsQFplemJn8X4jMa+xKVGiO8Lu81WNHrGK2USyu3gq3s7w9QlZYrYLniZCDCU+WB2JXFeKPyBYWjZSauoRKtKHFNmigQEf/px3/asZ5o3YqxR/FN+K233ppbgKK8c3R3iVaTGIAf38pGuebo1hbriBOv+KY1ThziWlDl8RM1EV2Z4nFRMjxObOIELFqNqhvTEiWe4wQ9vg2OktwxXidO4qN7TAwWryy2P4JliOsarYp4jWJsVLQqfOtb36rSlTFe5xi/EeuO1ym+3Y/XJMqsV26Rqk6E3+gWFa9blGqOa27FY8tluVcmTtSim1Hsc4y1ivAX+x3XYVpZWfCP87qvih/96EcV1+GJ90l094oAGCd+1V1XqKZiW2Mwf7w/40Q7Tj5jPOGKxmxFYYdoXY3WwigRHu/ReP2L7Ar2ccW4nOjOFeNooohEnKTHFxoxtnDp9/SaOIbRHS+25bTTTsvvs3ifxhc3NR2DFyf6EfrifRqPia7A0WUtgkYEtkMPPTR/fqM1OP4mxRcl8fmN54z9jpa4aJGJLnbx3PH+iS+BIqBXbkGOv1mxvni/xZioWH/lcZGrI4rDxDZEN+DoVhxfrMTfzPIFolfUmlSTvwvxdyTGVsUXP3HNsyjAEmMF49hFq1Mcv7isRHn/QrRIxX7H5zuOTXRvjS+z4vpg8eVW/K2NLwviueMzB6yCGlQUBJqoKOfctm3b0pw5c5a7zOGHH57LjM+YMSNPv/vuu6Vjjz22tOGGG+aS0VGyPco1l+8vlwg+88wzc5ngeGyULv7KV75Spcx2lASOcsZRTnrdddfNZa6ff/75akuxr7XWWtVu24QJE0pDhgwpdejQodS5c+dclrlctnrp0s+x7v322y+XdY593nzzzUtnn332MuuMUsuxPVEeOcopr4oohR3PHbdHH310mfWecsoppe222y6XF499it9/9rOfrXS9UWZ6+PDheR9jX6Mk80svvZRLgMfrs7Jy0lF+OsrtDx48OO97PO6qq66q8hzlx0ZJ7JWVx1+V172mpdjD+PHj877FeuN9sfvuu5cef/zxKsuUS7FHifWaijLo/fr1qyhTXt7G8mtTnccee6z0qU99qtSuXbtSjx49SqeeemrpwQcfXOb1XV4p9ur2L+ZXLuu/vFLs1ZXlXvpYhzFjxuSS6PE57NOnT+nnP/956fvf/34+xitT02O4vM9fddsefxsOPfTQUseOHfPnJ35/5plnavS+CDfccENp0003LbVo0WKZ1zl+j/dGrDf2L/Y3/jbF+zrE35943aL8eWxvLDdo0KDS3XffvUwJ97333jt/BuM5ymXZV/TZWdrSxzy88cYbeb3xfunSpUs+Dvfcc09e5z/+8Y/l7vOq/F2I13L//ffPZf7jshGxDQceeGB+H1T2wx/+MP99bt68eUVZ9lhm3333ze/leL/Ez4MPPrj0yiuvrPS4AFU1i39WJYwBNGXRtSlaeuLb3l/84hepoYuL8EY3zZqMOaPhi/LsUemwXGGOuhMXLY4LZkeBnGhpAhoHY64AVkGMY4kxDJUH+kN9HTNZWQSquN5UBGrq9ljEmKvo1tq3b1/BChoZY64AaiAqHP7zn//M46yibHP5mj9QX0UlzCidHj+j0maMJYprdp166ql1vWlNzv7775+vTxZjx2LMWBTFiUqXla+bBzQOwhVADcSJaZwQxcnRzTffXNebAysV1SzjsgFxodwoABHXQIuqetFawpoVFQOj6ESEqSguEkU14rqBNb2UA9BwGHMFAABQAGOuAAAACiBcAQAAFMCYq2osWbIkX9U+Lii5oov7AQAAjVupVMoX9Y5LscSFu1dEuKpGBKuePXvW9WYAAAD1xOTJk9NGG220wmWEq2pEi1X5BezYsWNdbw4AAFBHZs2alRteyhlhRYSrapS7AkawEq4AAIBmNRgupKAFAABAAYQrAACAAghXAAAABTDmCgAAGrjFixenhQsX1vVmNEgtWrRILVu2LOQSTMIVAAA0YLNnz07/+c9/8vWYWD3t27dP3bt3T61bt04fh3AFAAANuMUqglWEgy5duhTS+tKUlEqltGDBgvTOO++kN998M/Xt23elFwpeEeEKAAAaqOgKGAEhglW7du3qenMapHjdWrVqlSZOnJiDVtu2bVd7XQpaAABAA6fF6uP5OK1VVdZTyFoAAACaOOEKAACgAMIVAAA0cYuXlNLY199Nv332rfwzphuS3r17p8svv7yuN0NBCwAAaMpGPz8lnfe7CWnKzHkV87p3aptG7NMv7bl191p73s985jNp++23LyQUPfnkk2mttdZKdU3LFQAANOFgdfTt46sEqzB15rw8P+6vK6VSKS1atKhGy0a1xChHX9eEKwAAaCQikMxdsKhGtw/mLUwj7n8hVdcBsDzv3Psn5OVqsr7SKlzE+PDDD0+PPPJIuuKKK3Klw7jdfPPN+ecf//jH1L9//9SmTZv06KOPptdffz3tu+++qWvXrqlDhw5pxx13TH/+859X2C0w1vPzn/887bfffjl0xfWr7r///lTbdAsEAIBG4sOFi1O/cx4sZF0RlabOmpe2OfdPNVp+wsihqX3rmsWLCFWvvPJK2nrrrdPIkSPzvBdeeCH/PO2009Ill1ySNt1007TuuuumyZMnp7322iv9+Mc/zoHr1ltvTfvss096+eWX08Ybb7zc5zjvvPPSxRdfnH7yk5+kK6+8Mh1yyCH5Wlbrrbdeqi1argAAgDWqU6dOqXXr1rlVqVu3bvnWokWLfF+ErT322CP16dMnB6HtttsuHXnkkTmIRQvUD3/4w3zfylqionXs4IMPTptttlk6//zz0+zZs9O4ceNqdb+0XAEAQCPRrlWL3IJUE+Pe/G86/KYnV7rczcN3TAM3Wa9Gz12EAQMGVJmOUHTuueemBx54IE2ZMiWPw/rwww/TpEmTVriebbfdtuL3KHbRsWPHNH369FSbhCsAAGgkYqxRTbvm7dq3S64KGMUrqhst1Syl1K1T27xci+YxtWastVTVv5NPPjk99NBDuatgtEK1a9cufeUrX0kLFixY4XpatWq1zGuzZMmSVJt0CwQAgCYoAlOUWw9LR6fydNxfW8GqdevWafHixStd7rHHHstd/KI4xTbbbJO7EP773/9O9ZFwBQAATVRcx+qab+yQW6gqi+mYX5vXuerdu3d64oknclCaMWPGcluVYpzVqFGj0rPPPpuee+659PWvf73WW6BWl26B9VhcGTv6wk7/YF7aYO22ua/rmmySBQCg8YsAtUe/bmv8vPPkk09Ow4YNS/369ctjqG666aZql7vsssvSN7/5zbTTTjulzp07px/84Adp1qxZqT5qVlqVgvQF+9vf/pZLIz799NN5cNq9996bvvzlL6/wMQ8//HA66aSTcqnGnj17prPOOis3E1Z29dVX5/VOnTo1VxeJ0osDBw6s8XbFwYoKJjNnzswD35rSlbIBAGg45s2bl9588820ySabpLZtq7Y+UczruCrZoE67Bc6ZMyeHnwhDNRE7vPfee6fdd989Nwt+73vfS9/+9rfTgw/+r5b/XXfdlcPXiBEj0vjx4/P6hw4dWuuVQZrKlbIBAIB62HK1dPWOlbVcRRNglGB8/vnnK+Z97WtfS++//34aPXp0nh40aFC+avNVV12Vp6M/ZrRwHXfccfmCZPW95Sq6Au5y0V+WCVZl0TjbtWPb9NBJn9ZFkOWWQY3PEwDQ+Gm5ql8tVw1qzNXYsWPTkCFDqsyLVqlowQpRjjG6GJ5++ukV9zdv3jw/Jh67PPPnz8+3srrswxl9XZcXrFbnStk0PQN6rZt+fdRgAQsAYA1rUNUCYwxV165dq8yL6QhDMQguqoxEOcfqlonHLs8FF1yQ02j5Fi1ddSUGEcLH8dTE99KHC1de1hQAgGI1qJar2hItXTFOqyzCWl0FrKjOUhM1vVI2TcfcBYvTgB/9ua43AwCgyWpQ4SouGDZt2rQq82I6+j7GlZpbtGiRb9UtE49dnjZt2uRbfRCBqT5eKRsAAGhE3QIHDx6cxowZU2XeQw89lOeXr/Lcv3//KstEQYuYLi9T39X1lbIBAIAGGK5mz56dS6rHLUSFjvh90qRJFd31DjvssIrljzrqqPTGG2+kU089Nb300kvpZz/7Wbr77rvTiSeeWLFMdO+74YYb0i233JJefPHFdPTRR+eS78OHD08NRV1eKRsAAGiA3QKfeuqpfM2qsvK4p7hS880335wvLFwOWiFKI0Yp9ghTV1xxRdpoo43Sz3/+81wxsOyggw5K77zzTjrnnHNyEYvtt98+l2lfushFfVdXV8oGAAAa+HWu6pO6vM4VrK65Cxalfud8dEHtCSOHpvatG9SQSgCgLq9ztWRxShMfT2n2tJQ6dE2p104pNW+RmoomeZ0rAACgYBPuT2n0D1Ka9fb/5nXskdKeF6XU70u19rSf+cxnci+zyy+/vJD1HX744en9999P9913X6orDaqgBQAAUHCwuvuwqsEqzJry0fy4nxoTrgAAoLGIET8L5tTsNm9WSn88NR5U3Yo++hEtWrFcTdZXKq1SK9MjjzyS6yg0a9Ys3/7973+n559/Pn3hC19IHTp0yDUTDj300DRjxoyKx/3mN79J22yzTb4M0/rrr5+GDBmSi9ede+65uaDdb3/724r1Pfzww2lN0y0QAAAai4VzUzq/R0ErK33UonVhz5otfsbbKbVeq0aLRqh65ZVX0tZbb51GjhyZ57Vq1SoNHDgwffvb304//elP04cffph+8IMfpAMPPDD95S9/ycXuDj744HTxxRen/fbbL33wwQfp73//e4oSEieffHKuFB7jo2666aa8vvXWWy+tacIVAACwRnXq1Clfo7Z9+/apW7dued6PfvSj9MlPfjKdf/75FcvdeOONqWfPnjmIxWWcFi1alPbff//Uq1evfH+0YpVFa9b8+fMr1lcXhCsAAGgsWrX/qAWpJqI64B1fWflyh/zmo+qBNXnuj+G5555Lf/3rX3OXwKW9/vrr6fOf/3z63Oc+lwNVXIoppr/yla+kddddN9UXwhUAADQWzZrVuGte6vPZj6oCRvGKasddNfvo/lhuDZRlnz17dtpnn33SRRddtMx93bt3Ty1atEgPPfRQevzxx9Of/vSndOWVV6YzzzwzPfHEE7mEen2goAUAADRFEZii3HrWbKk7/296zwtrLVi1bt06LV68uGJ6hx12SC+88ELq3bt32myzzarc1lrro8AYhSp23nnndN5556Vnnnkmr+Pee++tdn11QbgCAICmKq5jdeCtKXXsXnV+tFjF/Fq8zlXv3r1zq1NUCYyKgMccc0z673//m4tWPPnkk7kr4IMPPpiGDx+eQ1MsG+OxnnrqqTRp0qQ0atSo9M4776Qtt9yyYn3//Oc/08svv5zXt3DhwrSm6RYIAABNWQSoLfb+aAzW7Gkpdej60RirWu4KePLJJ6dhw4alfv365cqAb775ZnrsscdyhcAYTxXFKaJwxZ577pmaN2+eOnbsmP72t7/liw5HVcC479JLL82l28MRRxyRy68PGDAgdzGM8VtxoeI1SbgCAICmLoLUJruu0af8xCc+kcaOHbvM/GiRqk60UI0ePXq56+vSpUsei1WXdAsEAAAogHAFAABQAOEKAACgAMIVAABAAYQrAABo4Eql6i4CzJp+/YQrAABooFq0+Khc+oIFC+p6Uxq0uXPn5p+tWrX6WOtRih0AABqoli1bpvbt2+eL6UYwiOtBsWotVhGspk+fntZZZ52KsLq6hCtoJBYv+V9z9rg3/5t27dsltWjerE63CQCoXc2aNUvdu3fPF+CdOHFiXW9OgxXBqlu3bh97PcIVNAKjn5+SRtz/QsX04Tc9mbp3aptG7NMv7bl19zrdNgCgdrVu3Tr17dtX18DVFC1+H7fFqky4gkYQrI6+fXxaehjm1Jnz8vxrvrGDgAUAjVx0B2zbtm1db0aTJ1xBA+8KeN7vJiwTrELMi06B594/Ie28WecadxFs16pF7mIAAMCqEa6gAYuxVVNmzlvu/RGwps6al7Y59081XueAXuumXx81WMACAFhFyolAAzb9g+UHq9X11MT30ocLFxe+XgCAxk7LFTRgG6xds77VNw/fMQ3cZL0VLjN3weI04Ed/LmjLAACaHuEKGrAITFEVMIpXVDfuKjr2devUVll2AIA1QLdAaMAiMEW59bB0dCpPx/2CFQBA7ROuoIGLMutRbj1aqCqLaWXYAQDWHN0CoRGIALVHv265emAUuYixWNFlUIsVAMCaI1xBIxFBanCf9et6MwAAmizdAgEAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAA0hnB19dVXp969e6e2bdumQYMGpXHjxi132YULF6aRI0emPn365OW32267NHr06CrLLF68OJ199tlpk002Se3atcvL/vCHP0ylUmkN7A0AANBU1Wm4uuuuu9JJJ52URowYkcaPH5/D0tChQ9P06dOrXf6ss85K1113XbryyivThAkT0lFHHZX222+/9Mwzz1Qsc9FFF6VrrrkmXXXVVenFF1/M0xdffHF+DAAAQG1pVqrDJp1oqdpxxx1zEApLlixJPXv2TMcdd1w67bTTllm+R48e6cwzz0zHHHNMxbwDDjggt1DdfvvtefqLX/xi6tq1a/rFL36x3GVWZtasWalTp05p5syZqWPHjgXsKdR/cxcsSv3OeTD/PmHk0NS+dcu63iQAgDq3KtmgzlquFixYkJ5++uk0ZMiQ/21M8+Z5euzYsdU+Zv78+bk7YGURmh599NGK6Z122imNGTMmvfLKK3n6ueeey/d/4QtfWO62xHrjRat8AwAAWBV19tX0jBkz8vioaGWqLKZfeumlah8TXQYvu+yy9OlPfzqPpYoQNWrUqLyesmjxinC0xRZbpBYtWuT7fvzjH6dDDjlkudtywQUXpPPOO6/AvQMAAJqaOi9osSquuOKK1Ldv3xycWrdunY499tg0fPjw3OJVdvfdd6c77rgj/fKXv8zjuG655ZZ0ySWX5J/Lc/rpp+dmvvJt8uTJa2iPAACAxqLOWq46d+6cW5amTZtWZX5Md+vWrdrHdOnSJd13331p3rx56d13381jsKKlatNNN61Y5pRTTsnzvva1r+XpbbbZJk2cODG3Tg0bNqza9bZp0ybfAAAAGlzLVbQ89e/fP3ftK4uCFjE9ePDgFT42xl1tuOGGadGiRemee+5J++67b8V9c+fOrdKSFSLExboBAABqS52WA4sy7NGaNGDAgDRw4MB0+eWXpzlz5uSufuGwww7LISpancITTzyR3nrrrbT99tvnn+eee24OTaeeemrFOvfZZ588xmrjjTdOW221VS7THuO0vvnNb9bZfgIAAI1fnYargw46KL3zzjvpnHPOSVOnTs2hKS4KXC5yMWnSpCqtUNEdMK519cYbb6QOHTqkvfbaK912221pnXXWqVgmrmcVFxH+7ne/m6+XFV0HjzzyyPwcAAAAjfI6V/WV61zRFLnOFQBAA73OFQAAQGMiXAEAABRAuAIAACiAcAUAAFAA4QrIFi/5X22bcW/+t8o0AAArJ1wBafTzU9KQyx6pmD78pifTLhf9Jc8HAKBmhCto4iJAHX37+DRt1vwq86fOnJfnC1gAADXjQjbQhEXXv/N+NyFV1wEw5jVLKZ17/4S082adU4vmMQUAsGa0a9UiNWvWsM4/hCtowmJs1ZSZ85Z7fwSsqbPmpW3O/dMa3S4AgAG91k2/PmpwgwpYugVCEzb9g+UHKwCAuvTUxPfShwsXp4ZEyxU0YRus3bZGy908fMc0cJP1an17AADmLlicBvzoz6khEq6gCYvA1L1T21y8orpxV9EI361T27Rr3y7GXAEArIRugdCERWAasU+//PvS0ak8HfcLVgAAKydcQRO359bd0zXf2CG3UFUW0zE/7gcAYOV0CwRygNqjX7dcPTCKXMRYrOgyqMUKAKDmhCsgiyA1uM/6db0ZAAANlm6BAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAAjSFcXX311al3796pbdu2adCgQWncuHHLXXbhwoVp5MiRqU+fPnn57bbbLo0ePXqZ5d566630jW98I62//vqpXbt2aZtttklPPfVULe8JAADQlNVpuLrrrrvSSSedlEaMGJHGjx+fw9LQoUPT9OnTq13+rLPOStddd1268sor04QJE9JRRx2V9ttvv/TMM89ULPPee++lnXfeObVq1Sr98Y9/zMtdeumlad11112DewYAADQ1zUqlUqmunjxaqnbcccd01VVX5eklS5aknj17puOOOy6ddtppyyzfo0ePdOaZZ6ZjjjmmYt4BBxyQW6duv/32PB2Pe+yxx9Lf//731d6uWbNmpU6dOqWZM2emjh07rvZ6AACAVTN3waLU75wH8+8TRg5N7Vu3THVpVbJBnbVcLViwID399NNpyJAh/9uY5s3z9NixY6t9zPz583N3wMoiWD366KMV0/fff38aMGBA+upXv5o22GCD9MlPfjLdcMMNK9yWWG+8aJVvAAAAq6LOwtWMGTPS4sWLU9euXavMj+mpU6dW+5joMnjZZZelV199NbdyPfTQQ2nUqFFpypQpFcu88cYb6Zprrkl9+/ZNDz74YDr66KPT8ccfn2655ZblbssFF1yQ02j5Fq1nAAAADaqgxaq44oorcmjaYostUuvWrdOxxx6bhg8fnlu8yiJ07bDDDun888/PrVbf+c530hFHHJGuvfba5a739NNPz8185dvkyZPX0B4BAACNRZ2Fq86dO6cWLVqkadOmVZkf0926dav2MV26dEn33XdfmjNnTpo4cWJ66aWXUocOHdKmm25asUz37t1Tv379qjxuyy23TJMmTVrutrRp0yb3n6x8AwAAaBDhKlqe+vfvn8aMGVOl1SmmBw8evMLHxrirDTfcMC1atCjdc889ad999624LyoFvvzyy1WWf+WVV1KvXr1qYS8AAAA+UqelN6IM+7Bhw3IBioEDB6bLL788t0pFV79w2GGH5RAVY6LCE088ka9htf322+ef5557bg5kp556asU6TzzxxLTTTjvlboEHHnhgvm7W9ddfn28AAACNMlwddNBB6Z133knnnHNOLmIRoSkuClwuchFd+SqPp5o3b16+1lUUrYjugHvttVe67bbb0jrrrFOxTJR2v/fee/M4qrjg8CabbJJD2yGHHFIn+wgAADQNdXqdq/rKda4AAKBuzHWdKwAAgKZNuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAVoWcRKqCVLFqc08fGUZk9LqUPXlHrtlFLzFnW9VTTW94v3GwDAxyJc1VcT7k9p9A9SmvX2/+Z17JHSnhel1O9LdbllNMb3i/cbAMDHpltgfRQnuncfVvVEN8ya8tH8uB+Ker94vwEAFELLVX0TXbOiBSGVqrkz5jX76P5NP6PLFh+9X/546uq/Xz7u4wEAirZgUWqX5qUPU5vU0AhX9U2MeVm6BaGK0kf3X9hzDW4UDdfHfb94vwEAa1b7lNKLbVN6csknUioNTQ2JboH1TRQTAACAJm7H5q+ktHBuaki0XNU3UaWtJg75zUfV3GjaoqXzjq+s/vvl4z4eAKBgc+fMSu2v2CI1RMJVfRMnsFGlLYoJVDsOptlH9/f5rDEwfPQ++Djvl4/7eACAoi1YlBoq3QLrmziBjfLXWbOl7vy/6T0vdKJLMe8X7zcAgMIIV/VRXFfowFtT6ti96vxoQYj5rjtEke8X7zcAgELoFlhfxQntFnt/NCYmilzEWKzoMqgFgdp4v3i/AQB8bMJVfRYntpvsWtdbQVN5v3i/AQB8LLoFAgAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgMYSrq6++urUu3fv1LZt2zRo0KA0bty45S67cOHCNHLkyNSnT5+8/HbbbZdGjx693OUvvPDC1KxZs/S9732vlrYeAACgHoSru+66K5100klpxIgRafz48TksDR06NE2fPr3a5c8666x03XXXpSuvvDJNmDAhHXXUUWm//fZLzzzzzDLLPvnkk3nZbbfddg3sCQAA0JTVebi67LLL0hFHHJGGDx+e+vXrl6699trUvn37dOONN1a7/G233ZbOOOOMtNdee6VNN900HX300fn3Sy+9tMpys2fPTocccki64YYb0rrrrruG9gYAAGiq6jRcLViwID399NNpyJAh/9ug5s3z9NixY6t9zPz583N3wMratWuXHn300SrzjjnmmLT33ntXWffyxDpnzZpV5QYAANBgwtWMGTPS4sWLU9euXavMj+mpU6dW+5joMhitXa+++mpasmRJeuihh9KoUaPSlClTKpa58847cxfDCy64oEbbEct16tSp4tazZ8+PuWcAAEBTU+fdAlfVFVdckfr27Zu22GKL1Lp163TsscfmLoXR4hUmT56cTjjhhHTHHXcs08K1PKeffnqaOXNmxS3WAQAA0GDCVefOnVOLFi3StGnTqsyP6W7dulX7mC5duqT77rsvzZkzJ02cODG99NJLqUOHDnn8VYhuhlEMY4cddkgtW7bMt0ceeST9v//3//Lv0VK2tDZt2qSOHTtWuQEAADSYcBUtT/37909jxoypmBdd/WJ68ODBK3xstEptuOGGadGiRemee+5J++67b57/uc99Lv3rX/9Kzz77bMVtwIABubhF/B5hDgAAoGgtUx2LMuzDhg3LAWjgwIHp8ssvz61S0dUvHHbYYTlElcdPPfHEE+mtt95K22+/ff557rnn5kB26qmn5vvXXnvttPXWW1d5jrXWWiutv/76y8wHAABoNOHqoIMOSu+8804655xzchGLCE1xUeBykYtJkyZVjKcK8+bNy9e6euONN3J3wCjDHuXZ11lnnTrcCwAAoKlrViqVSnW9EfVNlGKPqoFR3ML4KwAAWHPmzp6Z2l+y8Ue/nzwpte/QqcFkgwZXLRAAAKA+Eq4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACoNxYv+V8x86cmvldlur4TrgAAgHph9PNT0hevfLRi+sjbnk67XPSXPL8hEK4AAIA6N/r5Keno28en6R/MrzJ/6sx5eX5DCFjCFQAAUKcWLyml8343IVXXAbA8L+6v710EhSsAAKBOjXvzv2nKzHnLvT8iVdwfy9VnwhUAAFCnpn8wr9Dl6opwBQAA1KkN1m5b6HJ1RbgCAADq1MBN1kvdO7VNzZZzf8yP+2O5+ky4AgAA6lSL5s3SiH365d+XDljl6bg/lqvPhCsAAKDO7bl193TNN3ZIXTtW7frXrVPbPD/ur+9a1vUGAAAAhAhQe2y2W0oX5sl08+ED04BPbFTvW6zKhCsAAKDeaFEpSA3adL2UGkiwWu1ugX/961+L3xIAAIAGbLXC1Z577pn69OmTfvSjH6XJkycXv1UAAABNIVy99dZb6dhjj02/+c1v0qabbpqGDh2a7r777rRgwYLitxAAAKCxhqvOnTunE088MT377LPpiSeeSJ/4xCfSd7/73dSjR490/PHHp+eee674LQUAAGjMpdh32GGHdPrpp+eWrNmzZ6cbb7wx9e/fP+26667phRdeKGYrAQAAGmu4WrhwYe4WuNdee6VevXqlBx98MF111VVp2rRp6bXXXsvzvvrVrxa7tQAAAI2pFPtxxx2XfvWrX6VSqZQOPfTQdPHFF6ett9664v611lorXXLJJbmbIAAAQFOwWuFqwoQJ6corr0z7779/atOmzXLHZSnZDgAANBWrFa7GjBmz8hW3bJl222231Vk9AABA0xhzdcEFF+TCFUuLeRdddFER2wUAAND4w9V1112Xtthii2Xmb7XVVunaa68tYrsAAAAaf7iaOnVq6t69+zLzu3TpkqZMmVLEdgEAADT+cNWzZ8/02GOPLTM/5qkQCAAANEWrVdDiiCOOSN/73vfyta4++9nPVhS5OPXUU9P3v//9orcRAACgcYarU045Jb377rvpu9/9blqwYEGe17Zt2/SDH/wgnX766UVvIwAAQL3XrBRXAl5Ns2fPTi+++GJq165d6tu373KvedXQzJo1K3Xq1CnNnDkzdezYsa43BwAAmo4Fc1I6//+GGp3xdkqt12ow2WC1Wq7KOnTokHbcccePswoAAIBGYbXD1VNPPZXuvvvuNGnSpIqugWWjRo0qYtsAAAAad7XAO++8M+200065S+C9996bC1u88MIL6S9/+UtuMgMAAGhqVitcnX/++emnP/1p+t3vfpdat26drrjiivTSSy+lAw88MG288cbFbyUAAEBjDFevv/562nvvvfPvEa7mzJmTmjVrlk488cR0/fXXF72NAAAAjTNcrbvuuumDDz7Iv2+44Ybp+eefz7+///77ae7cucVuIQAAQGMtaPHpT386PfTQQ2mbbbZJX/3qV9MJJ5yQx1vFvM997nPFbyUAAEBjDFdXXXVVmjdvXv79zDPPTK1atUqPP/54OuCAA9JZZ51V9DYCAAA0vnC1aNGi9Pvf/z4NHTo0Tzdv3jyddtpptbFtAAAAjXfMVcuWLdNRRx1V0XIFAADAaha0GDhwYHr22WeL3xoAAICmNObqu9/9bjrppJPS5MmTU//+/dNaa61V5f5tt922qO0DAABovOHqa1/7Wv55/PHHV8yL61yVSqX8c/HixcVtIQAAQGMNV2+++WbxWwIAANDUwlWvXr2K3xIAAICmFq5uvfXWFd5/2GGHre72AAAANJ1wdcIJJ1SZXrhwYZo7d25q3bp1at++vXAFAAA0OatViv29996rcps9e3Z6+eWX0y677JJ+9atfFb+VAAAAjTFcVadv377pwgsvXKZVCwAAoCkoLFyFli1bprfffrvIVQIAADTeMVf3339/lem4vtWUKVPSVVddlXbeeeeitg0AAKBxh6svf/nLVabjwsFdunRJn/3sZ9Oll15a1LYBAAA07nC1ZMmS4rcEAACgASt0zBUAAEBTtVrh6oADDkgXXXTRMvMvvvji9NWvfrWI7QIAAGj84epvf/tb2muvvZaZ/4UvfCHfBwAA0NSsVriKiwa3bt16mfmtWrVKs2bNKmK7AAAAGn+42mabbdJdd921zPw777wz9evXr4jtAgAAaPzVAs8+++y0//77p9dffz2XXw9jxoxJv/rVr9Kvf/3rorcRAACgcYarffbZJ913333p/PPPT7/5zW9Su3bt0rbbbpv+/Oc/p9122634rQQAAGiM4Srsvffe+QYAAMBqjrl68skn0xNPPLHM/Jj31FNPrfL6rr766tS7d+/Utm3bNGjQoDRu3LjlLrtw4cI0cuTI1KdPn7z8dtttl0aPHl1lmQsuuCDtuOOOae21104bbLBB+vKXv5xefvnlVd4uAACAWg1XxxxzTJo8efIy8996661836qIwhgnnXRSGjFiRBo/fnwOS0OHDk3Tp0+vdvmzzjorXXfddenKK69MEyZMSEcddVTab7/90jPPPFOxzCOPPJK34x//+Ed66KGHciD7/Oc/n+bMmbMaewsAALByzUqlUimtog4dOqR//vOfadNNN60y/80338xjrz744IMarytaqqKV6aqrrsrTS5YsST179kzHHXdcOu2005ZZvkePHunMM8+sEuLiosYx7uv222+v9jneeeed3IIVoevTn/70Srcpysl36tQpzZw5M3Xs2LHG+wIAAHxMC+akdH6Pj34/4+2UWq+V6tKqZIPVarlq06ZNmjZt2jLzp0yZklq2rPkwrgULFqSnn346DRky5H8b1Lx5nh47dmy1j5k/f37uDlhZBKtHH310uc8TL0RYb731lrvOeNEq3wAAAFbFaoWr6GJ3+umnV4SW8P7776czzjgj7bHHHjVez4wZM9LixYtT165dq8yP6alTp1b7mOgyeNlll6VXX301t3JFt79Ro0blYFedWOZ73/te2nnnndPWW29d7TIxRivSaPkWLWcAAAC1Hq4uueSSPOaqV69eaffdd8+3TTbZJAeiSy+9NNWmK664IvXt2zdtscUWqXXr1unYY49Nw4cPzy1e1Ynug88//3y+wPHylINi+VbdeDIAAIDCS7FvuOGGeczVHXfckZ577rncLS8CzsEHH5xatWpV4/V07tw5tWjRYpkuhjHdrVu3ah/TpUuXfI2tefPmpXfffTePwYqxWUuP/woRvH7/+9+nv/3tb2mjjTZaYTfHuAEAAKzRlquw1lprpV122SVfUDiKRKyzzjrpj3/8Y7r//vtrvI5oeerfv38aM2ZMlW58MT148OAVPjbGXUXIW7RoUbrnnnvSvvvuW3Ff1OiIYHXvvfemv/zlL7lVDQAAoN61XL3xxhu5/Pm//vWv1KxZsxxm4mdZjKOqqSjDPmzYsDRgwIA0cODAdPnll+eS6dESFg477LAcomJcVPlaWlHyffvtt88/zz333BzITj311CpdAX/5y1+m3/72t/laV+XxWzGeKlrZAAAA6kXL1QknnJBbg+JaVO3bt89jmqLMeQSkhx9+eJXWddBBB+UxXOecc04OTM8++2y+KHC5yMWkSZOqFKuI7oBxrat+/frlgBfBKyoFRstZ2TXXXJPHTn3mM59J3bt3r7jFNbUAAADqzXWuYqxUdLeLa1pFa9C4cePS5ptvnud9//vfr3JB34bIda4AAKCOLGhi17mKbn/R3a4ctN5+++38e1QPfPnll1dnlQAAAE1vzFVcLyqqBEbXwEGDBqWLL744F6e4/vrrq63aBwAA0NitVriKMU9RdCKMHDkyffGLX0y77rprWn/99Y1rAgAAmqTVCldDhw6t+H2zzTZLL730Uvrvf/+b1l133SpVAwEAAJqK1QpX1VlvvfWKWhUAAEDTuYgwAAAA/yNcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAANBYwtXVV1+devfundq2bZsGDRqUxo0bt9xlFy5cmEaOHJn69OmTl99uu+3S6NGjP9Y6AQAAGny4uuuuu9JJJ52URowYkcaPH5/D0tChQ9P06dOrXf6ss85K1113XbryyivThAkT0lFHHZX222+/9Mwzz6z2OgEAAD6uZqVSqZTqULQq7bjjjumqq67K00uWLEk9e/ZMxx13XDrttNOWWb5Hjx7pzDPPTMccc0zFvAMOOCC1a9cu3X777au1zqXNmjUrderUKc2cOTN17NixwL0FAABWaMGclM7v8dHvZ7ydUuu1Ul1alWxQpy1XCxYsSE8//XQaMmTI/zaoefM8PXbs2GofM3/+/NzVr7IIVo8++ujHWme8aJVvAAAAq6JOw9WMGTPS4sWLU9euXavMj+mpU6dW+5jo3nfZZZelV199NbdIPfTQQ2nUqFFpypQpq73OCy64IKfR8i1auQAAABrUmKtVdcUVV6S+ffumLbbYIrVu3Tode+yxafjw4bl1anWdfvrpuZmvfJs8eXKh2wwAADR+dRquOnfunFq0aJGmTZtWZX5Md+vWrdrHdOnSJd13331pzpw5aeLEiemll15KHTp0SJtuuulqr7NNmza5/2TlGwAAQIMJV9Hy1L9//zRmzJiKedHVL6YHDx68wsfGuKsNN9wwLVq0KN1zzz1p3333/djrBAAAWF0tUx2LkunDhg1LAwYMSAMHDkyXX355bpWKrn7hsMMOyyEqxkWFJ554Ir311ltp++23zz/PPffcHJ5OPfXUGq8TAACg0YWrgw46KL3zzjvpnHPOyQUnIjTFRYHLBSkmTZpUZTzVvHnz8rWu3njjjdwdcK+99kq33XZbWmeddWq8TgAAgEZ3nav6yHWuAACgjixwnSsAAIAmTbgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAABpDuLr66qtT7969U9u2bdOgQYPSuHHjVrj85ZdfnjbffPPUrl271LNnz3TiiSemefPmVdy/ePHidPbZZ6dNNtkkL9OnT5/0wx/+MJVKpTWwNwAAQFPVsi6f/K677konnXRSuvbaa3OwiuA0dOjQ9PLLL6cNNthgmeV/+ctfptNOOy3deOONaaeddkqvvPJKOvzww1OzZs3SZZddlpe56KKL0jXXXJNuueWWtNVWW6WnnnoqDR8+PHXq1Ckdf/zxdbCXAABAU1CnLVcRiI444ogcfvr165dDVvv27XN4qs7jjz+edt555/T1r389t3Z9/vOfTwcffHCV1q5YZt9990177713XuYrX/lKXm5lLWIAAAANMlwtWLAgPf3002nIkCH/25jmzfP02LFjq31MtFbFY8pB6Y033kh/+MMf0l577VVlmTFjxuRWrfDcc8+lRx99NH3hC19Y7rbMnz8/zZo1q8oNAACgQXQLnDFjRh4f1bVr1yrzY/qll16q9jHRYhWP22WXXfIYqkWLFqWjjjoqnXHGGRXLRLfBCEdbbLFFatGiRX6OH//4x+mQQw5Z7rZccMEF6bzzzitw7wAAgKamzgtarIqHH344nX/++elnP/tZGj9+fBo1alR64IEHcsGKsrvvvjvdcccdeXxWLBNjry655JL8c3lOP/30NHPmzIrb5MmT19AeAQAAjUWdtVx17tw5tyxNmzatyvyY7tatW7WPiSqAhx56aPr2t7+dp7fZZps0Z86c9J3vfCedeeaZuVvhKaeckluvvva1r1UsM3HixNw6NWzYsGrX26ZNm3wDAABocC1XrVu3Tv3798/jo8qWLFmSpwcPHlztY+bOnZsDVGUR0EK51Prylol1AwAANMpS7FGGPVqTBgwYkAYOHJhLsUdLVFQPDIcddljacMMNc6tT2GeffXKFwU9+8pO5dPtrr72WW7Nifjlkxe8xxmrjjTfOpdifeeaZ/JhvfvObdbmrAABAI1en4eqggw5K77zzTjrnnHPS1KlT0/bbb59Gjx5dUeRi0qRJVVqhzjrrrHxNq/j51ltvpS5dulSEqbIrr7wyB67vfve7afr06alHjx7pyCOPzM8BAABQW5qVyv3pqBDVBuOiw1HcomPHjnW9OQAA0HQsmJPS+T0++v2Mt1NqvVaDyQYNqlogAABAfSVcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAaQ7i6+uqrU+/evVPbtm3ToEGD0rhx41a4/OWXX54233zz1K5du9SzZ8904oknpnnz5lVZ5q233krf+MY30vrrr5+X22abbdJTTz1Vy3sCAAA0ZS3r8snvuuuudNJJJ6Vrr702B6sITkOHDk0vv/xy2mCDDZZZ/pe//GU67bTT0o033ph22mmn9Morr6TDDz88NWvWLF122WV5mffeey/tvPPOaffdd09//OMfU5cuXdKrr76a1l133TrYQwAAoKmo03AVgeiII45Iw4cPz9MRsh544IEcniJELe3xxx/PwenrX/96no4Wr4MPPjg98cQTFctcdNFFuUXrpptuqpi3ySabrJH9AQAAmq466xa4YMGC9PTTT6chQ4b8b2OaN8/TY8eOrfYx0VoVjyl3HXzjjTfSH/7wh7TXXntVLHP//fenAQMGpK9+9au59euTn/xkuuGGG1a4LfPnz0+zZs2qcgMAAGgQ4WrGjBlp8eLFqWvXrlXmx/TUqVOrfUy0WI0cOTLtsssuqVWrVqlPnz7pM5/5TDrjjDMqlonAdc0116S+ffumBx98MB199NHp+OOPT7fccstyt+WCCy5InTp1qrhFyxcAAECDKmixKh5++OF0/vnnp5/97Gdp/PjxadSoUbkb4Q9/+MOKZZYsWZJ22GGHvFy0Wn3nO9/JXQ+jy+HynH766WnmzJkVt8mTJ6+hPQIAABqLOhtz1blz59SiRYs0bdq0KvNjulu3btU+5uyzz06HHnpo+va3v52nowrgnDlzcoA688wzc7fC7t27p379+lV53JZbbpnuueee5W5LmzZt8g0AAKDBtVy1bt069e/fP40ZM6ZKq1NMDx48uNrHzJ07NweoyiKghVKplH9GwYuoNlhZVBXs1atXLewFAABAPagWGGXYhw0blgtQDBw4MJdij5aocvXAww47LG244YZ5TFTYZ599coXB6O4Xpdtfe+213JoV88shK657FYUvolvggQcemItfXH/99fkGAADQKMPVQQcdlN555510zjnn5CIW22+/fRo9enRFkYtJkyZVaak666yz8jWt4mdcKDiuYRXB6sc//nHFMjvuuGO699578ziqKH4RZdgjtB1yyCF1so8AAEDT0KxU7k9HhSjFHlUDo7hFx44d63pzAACg6VgwJ6Xze3z0+xlvp9R6rQaTDRpUtUAAAID6SrgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACAAghXAAAABRCuAAAACiBcAQAAFEC4AgAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKg/liz+3+8TH686Xc8JVwAAQP0w4f6Urh74v+k7vpLS5Vt/NL8BEK4AAIC6N+H+lO4+LKUPplSdP2vKR/MbQMASrgAAgLq1ZHFKo3+QUipVc+f/zRt9Wr3vIihcAQAAdWvi4ynNensFC5RSmvXWR8vVY8IVAABQt2ZPK3a5OiJcAQAAdatD12KXqyPCFQAAULd67ZRSxx4ppWbLWaBZSh03/Gi5eky4AgAA6lbzFintedH/TSwdsP5ves8LP1quHhOuAACAutfvSykdeGtKHbtXnR8tWjE/7q/nWtb1BgAAAGQRoLbY+6OqgFG8IsZYRVfAet5iVSZcAQAA9UfzFiltsmtqiHQLBAAAKIBwBQAAUADhCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QoAAKAAwhUAAEABhCsAAIACCFcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAVoWsZLGplQq5Z+zZs2q600BAADqUDkTlDPCighX1fjggw/yz549e9b1pgAAAPUkI3Tq1GmFyzQr1SSCNTFLlixJb7/9dlp77bVTs2bN6jwpR8ibPHly6tixY51uCx9xTOofx6T+cUzqH8ek/nFM6h/HpP6ZVQ+OScSlCFY9evRIzZuveFSVlqtqxIu20UYbpfok3kw+5PWLY1L/OCb1j2NS/zgm9Y9jUv84JvVPxzo+JitrsSpT0AIAAKAAwhUAAEABhKt6rk2bNmnEiBH5J/WDY1L/OCb1j2NS/zgm9Y9jUv84JvVPmwZ2TBS0AAAAKICWKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuKoDV199derdu3dq27ZtGjRoUBo3btwKl//1r3+dtthii7z8Nttsk/7whz9UuT9qkpxzzjmpe/fuqV27dmnIkCHp1VdfreW9aFyKPiajRo1Kn//859P666+fmjVrlp599tla3oPGp8hjsnDhwvSDH/wgz19rrbXyFdYPO+yw9Pbbb6+BPWk8iv6cnHvuufn+OCbrrrtu/tv1xBNP1PJeNC5FH5PKjjrqqPz36/LLL6+FLW+8ij4mhx9+eD4OlW977rlnLe9F41Ibn5MXX3wxfelLX8oXlo2/YTvuuGOaNGlSLe5F43J1wcdk6c9I+faTn/wkrXFRLZA158477yy1bt26dOONN5ZeeOGF0hFHHFFaZ511StOmTat2+ccee6zUokWL0sUXX1yaMGFC6ayzziq1atWq9K9//atimQsvvLDUqVOn0n333Vd67rnnSl/60pdKm2yySenDDz9cg3vWcNXGMbn11ltL5513XumGG26IapylZ555Zg3uUcNX9DF5//33S0OGDCndddddpZdeeqk0duzY0sCBA0v9+/dfw3vWcNXG5+SOO+4oPfTQQ6XXX3+99Pzzz5e+9a1vlTp27FiaPn36Gtyzhqs2jknZqFGjStttt12pR48epZ/+9KdrYG8ah9o4JsOGDSvtueeepSlTplTc/vvf/67BvWrYauOYvPbaa6X11luvdMopp5TGjx+fp3/7298ud53U/jGp/PmIW6y7WbNm+f+XNU24WsPihO6YY46pmF68eHH+z+uCCy6odvkDDzywtPfee1eZN2jQoNKRRx6Zf1+yZEmpW7dupZ/85CcV98eJZJs2bUq/+tWvam0/GpOij0llb775pnBVz45J2bhx4/KxmThxYoFb3nitiWMyc+bMfEz+/Oc/F7jljVdtHZP//Oc/pQ033DAH3l69eglXdXxMIlztu+++tbjVjVttHJODDjqo9I1vfKMWt7pxG7gG/j+Jz8xnP/vZUl3QLXANWrBgQXr66adz15ey5s2b5+mxY8dW+5iYX3n5MHTo0Irl33zzzTR16tQqy0QTdTSxLm+d1O4xoWEck5kzZ+YuA+uss06BW984rYljEs9x/fXX579f2223XcF70PjU1jFZsmRJOvTQQ9Mpp5ySttpqq1rcg8anNj8nDz/8cNpggw3S5ptvno4++uj07rvv1tJeNC61cUziM/LAAw+kT3ziE3l+HJc457rvvvtqeW8ahwVr4P+TadOm5WP0rW99K9UF4WoNmjFjRlq8eHHq2rVrlfkxHQGpOjF/RcuXf67KOqndY0L9Pybz5s3LY7AOPvjg1LFjxwK3vnGqzWPy+9//PnXo0CH3o//pT3+aHnroodS5c+da2IvGpbaOyUUXXZRatmyZjj/++Fra8sarto5JjK+69dZb05gxY/LxeeSRR9IXvvCF/Fys+WMyffr0NHv27HThhRfmY/OnP/0p7bfffmn//ffPx4a6/z/+lltuSWuvvXY+JnWhZZ08K0AdieIWBx54YC4Ec80119T15jR5u+++ey74Ev/h3nDDDfnYRFGL+DaYNSu+Tb7iiivS+PHjc6su9cPXvva1it9jIP+2226b+vTpk1uzPve5z9XptjVF0XIV9t1333TiiSfm37fffvv0+OOPp2uvvTbttttudbyF3HjjjemQQw7JX9rVBS1Xa1B8G9uiRYvcXFlZTHfr1q3ax8T8FS1f/rkq66R2jwn195iUg9XEiRNzC4lWq7o/JlFla7PNNkuf+tSn0i9+8YvcahI/WfPH5O9//3v+Vn7jjTfOxyFu8Vn5/ve/n6t6UT/+P9l0003zc7322msFbXnjVRvHJNYZn41+/fpVWWbLLbdULbAefE7+/ve/p5dffjl9+9vfTnVFuFqDWrdunfr375+b9it/AxLTgwcPrvYxMb/y8iFOCsvLb7LJJvnNVXmZWbNm5W9+l7dOaveYUD+PSTlYxWUK/vznP+cy+dS/z0msd/78+QVteeNVG8ckxlr985//zC2J5VtctiDGXz344IO1vEcN35r6nPznP//JY67i8ius+WMS64yy63ECX9krr7ySevXqVSv70Zi0ruXPSXw5F+uv07G7dVJGo4mXn4xKfjfffHMuJ/md73wnl5+cOnVqvv/QQw8tnXbaaVXKT7Zs2bJ0ySWXlF588cXSiBEjqi3FHuuIMqD//Oc/c4UUpdjr9pi8++67uULgAw88kKufxXPEdJQHZc0fkwULFuRLFGy00UalZ599tkq51vnz59fZfjblYzJ79uzS6aefnsvi//vf/y499dRTpeHDh+fniCp11M3frqWpFli3x+SDDz4onXzyyflzEtVno5LmDjvsUOrbt29p3rx5dbafTf1zEpcqiHnXX3996dVXXy1deeWVuVT43//+9zrZx4bmzlr62xUVZ9u3b1+65pprSnVJuKoD8SHceOONc43/KEf5j3/8o+K+3XbbLZddrezuu+8ufeITn8jLb7XVVvmEvbIox3722WeXunbtmt+sn/vc50ovv/zyGtufxqDoY3LTTTflULX0Lf4gsOaPSbkkfnW3v/71r2t0vxqyIo9JfPmz33775fK7cX/37t1zAI4S+dTd366lCVd1e0zmzp1b+vznP1/q0qVLPpmM4xHXBCqfhFJ3n5Nf/OIXpc0226zUtm3bfE24uNYoNVcbx+S6664rtWvXLl+SqC41i3/qrt0MAACgcTDmCgAAoADCFQAAQAGEKwAAgAIIVwAAAAUQrgAAAAogXAEAABRAuAIAACiAcAUAAFAA4QqAJuff//53atasWXr22Wdr/Jibb745rbPOOrW6XQA0bMIVAABAAYQrAACAAghXADRKo0ePTrvsskvuyrf++uunL37xi+n111+vdtmHH344dxN84IEH0rbbbpvatm2bPvWpT6Xnn39+mWUffPDBtOWWW6YOHTqkPffcM02ZMqXivieffDLtscceqXPnzqlTp05pt912S+PHj6/V/QSg/hCuAGiU5syZk0466aT01FNPpTFjxqTmzZun/fbbLy1ZsmS5jznllFPSpZdemkNSly5d0j777JMWLlxYcf/cuXPTJZdckm677bb0t7/9LU2aNCmdfPLJFfd/8MEHadiwYenRRx9N//jHP1Lfvn3TXnvtlecD0Pi1rOsNAIDacMABB1SZvvHGG3NgmjBhQm51qs6IESNyy1O45ZZb0kYbbZTuvffedOCBB+Z5EbSuvfba1KdPnzx97LHHppEjR1Y8/rOf/WyV9V1//fW55eyRRx7JLWcANG5argBolF599dV08MEHp0033TR17Ngx9e7dO8+P1qblGTx4cMXv6623Xtp8883Tiy++WDGvffv2FcEqdO/ePU2fPr1ietq0aemII47ILVbRLTCed/bs2St8TgAaDy1XADRK0aWvV69e6YYbbkg9evTI3QG33nrrtGDBgtVeZ6tWrapMxzitUqlUMR1dAt999910xRVX5Odu06ZNDmwf5zkBaDiEKwAanQg4L7/8cg5Wu+66a54X46BWJsZJbbzxxvn39957L73yyiu5eEVNPfbYY+lnP/tZHmcVJk+enGbMmLHa+wFAwyJcAdDorLvuurlCYIx5iq570S3vtNNOW+njYvxUPK5r167pzDPPzFX/vvzlL9f4eaM7YBS7GDBgQJo1a1YukNGuXbuPuTcANBTGXAHQ6ERlwDvvvDM9/fTTuSvgiSeemH7yk5+s9HEXXnhhOuGEE1L//v3T1KlT0+9+97vUunXrGj/vL37xi9zitcMOO6RDDz00HX/88WmDDTb4mHsDQEPRrFS5szgANEFxnavdd989B6Oo7gcAq0PLFQAAQAGEKwAAgALoFggAAFAALVcAAAAFEK4AAAAKIFwBAAAUQLgCAAAogHAFAABQAOEKAACgAMIVAABAAYQrAACA9PH9f3IubB6jyA/JAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 27. Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and visualize its effect on accuracy.\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "X,y=load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "path=clf.cost_complexity_pruning_path(X_train,y_train)\n",
    "ccp_alphas,impurities=path.ccp_alphas,path.impurities\n",
    "\n",
    "clfs=[]\n",
    "for clf_alpha in ccp_alphas:\n",
    "    clf=DecisionTreeClassifier(ccp_alpha=clf_alpha,random_state=1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "clfs=clfs[:-1]\n",
    "ccp_alphas=ccp_alphas[:-1]\n",
    "\n",
    "train_scores=[accuracy_score(y_train,clf.predict(X_train))for clf in clfs]\n",
    "test_scores=[accuracy_score(y_test,clf.predict(X_test))for clf in clfs]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(ccp_alphas,train_scores,marker=\"o\",label=\"train\",drawstyle=\"steps-post\")\n",
    "plt.plot(ccp_alphas,test_scores,marker=\"o\",label=\"test\",drawstyle=\"steps-post\")\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs alpha for training and testing sets')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Precision: 0.97\n",
      "------------------\n",
      "Recall: 0.93\n",
      "------------------\n",
      "F1 score: 0.95\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# 28. Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision, Recall, and F1-Score.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier(criterion=\"gini\")\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "Precision = precision_score(y_test, y_pred)\n",
    "Recall=recall_score(y_test,y_pred)\n",
    "F1_score=f1_score(y_test,y_pred)\n",
    "print(\"------\" * 3)\n",
    "print(f\"Precision: {Precision:.2f}\")\n",
    "print(\"------\" * 3)\n",
    "\n",
    "print(f\"Recall: {Recall:.2f}\")\n",
    "print(\"------\" * 3)\n",
    "print(f\"F1 score: {F1_score:.2f}\")\n",
    "print(\"------\" * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 29. Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "clf=DecisionTreeClassifier(criterion=\"gini\")\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\",cmap=\"Blues\",cbar=False,\n",
    "            xticklabels=clf.classes_,yticklabels=clf.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 5}\n",
      "Best F1 Score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# 30. Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values for max_depth and min_samples_split.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X,y=load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "clf=DecisionTreeClassifier()\n",
    "\n",
    "grid=GridSearchCV(estimator=clf,param_grid=params,cv=5,verbose=3,n_jobs=-1,scoring=\"f1\")\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid.best_params_}\")\n",
    "print(f\"Best F1 Score: {grid.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
